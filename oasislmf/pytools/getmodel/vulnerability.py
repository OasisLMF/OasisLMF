import os
from math import ceil
import numpy as np
import numba as nb
import pyarrow as pa
import pyarrow.parquet as pq
import pathlib
import argparse
import logging

logger = logging.getLogger(__name__)
logger.addHandler(logging.NullHandler())


vulnerability_filename = 'vulnerability.bin'
vulnerability_dataset = "vulnerability_dataset"
vulnerability_parquet_filename = 'part_{}.parquet'

areaperil_int = np.dtype(os.environ.get('AREAPERIL_TYPE', 'u4'))
oasis_float = np.dtype(os.environ.get('OASIS_FLOAT', 'f4'))

Vulnerability = nb.from_dtype(np.dtype([('vulnerability_id', np.int32),
                                        ('intensity_bin_id', np.int32),
                                        ('damage_bin_id', np.int32),
                                        ('probability', oasis_float)
                                       ]))

vulnerability_bloc_size = int(os.environ.get('VULNERABILITY_BLOC_SIZE', 1e9)) # Bytes


@nb.njit(cache=True)
def get_vuln_info(vulns_bin):
    vulnerability_ids_set = set()
    num_intensity_bins = 0
    num_damage_bins = 0

    for vuln_i in range(vulns_bin.shape[0]):
        vuln = vulns_bin[vuln_i]
        vulnerability_ids_set.add(vuln['vulnerability_id'])
        if num_intensity_bins < vuln['intensity_bin_id']:
            num_intensity_bins = vuln['intensity_bin_id']

        if num_damage_bins < vuln['damage_bin_id']:
            num_damage_bins = vuln['damage_bin_id']

    return len(vulnerability_ids_set), num_intensity_bins, num_damage_bins


@nb.njit()
def get_array(vulns_bin, num_intensity_bins, num_damage_bins, max_vulnerability_id_size):
    """
    Numba: cannot cache generator for the moment
    to work properlly, data on the same vulnerability_id must all be in one block"""
    vulnerability_ids = np.empty(max_vulnerability_id_size, dtype=np.int32)
    vuln_array = np.zeros((vulnerability_ids.shape[0], num_damage_bins, num_intensity_bins), dtype=oasis_float)

    cursor = 0
    vulnerability_id_index = 0
    vulnerability_id = -1

    while cursor < vulns_bin.shape[0]:
        vuln = vulns_bin[cursor]
        if vuln['vulnerability_id'] != vulnerability_id:
            if vulnerability_id_index == max_vulnerability_id_size:
                yield vulnerability_ids, vuln_array
                vuln_array.fill(0)
                vulnerability_id_index = 0
            vulnerability_id = vulns_bin[cursor]['vulnerability_id']
            vulnerability_ids[vulnerability_id_index] = vulnerability_id
            cur_vuln_array = vuln_array[vulnerability_id_index]
            vulnerability_id_index += 1

        cur_vuln_array[vuln['damage_bin_id'] - 1, vuln['intensity_bin_id'] - 1] = vuln['probability']
        cursor+=1
    if vulnerability_id_index:
        yield vulnerability_ids[:vulnerability_id_index], vuln_array[:vulnerability_id_index]


def iter_table(vulns_bin, num_intensity_bins, num_damage_bins, info, max_vulnerability_id_size):
    for vulnerability_ids, vuln_array in get_array(vulns_bin, num_intensity_bins, num_damage_bins, max_vulnerability_id_size):
        arr_vulnerability_ids = pa.array(vulnerability_ids)
        arr_vulnerability = pa.FixedSizeListArray.from_arrays(vuln_array.ravel(), num_intensity_bins * num_damage_bins)
        vulnerability_table = pa.Table.from_arrays([arr_vulnerability_ids, arr_vulnerability], names=['vulnerability_id', 'vuln_array'], metadata=info)
        yield vulnerability_table


def vulnerability_to_parquet(run_dir):
    logger.debug(f'retrieving vulnerability info from {os.path.join(run_dir, vulnerability_filename)}')
    vulns_bin = np.memmap(os.path.join(run_dir, vulnerability_filename), dtype=Vulnerability, offset=4, mode='r')
    num_vulnerability_id, num_intensity_bins, num_damage_bins = get_vuln_info(vulns_bin)

    info = {"num_vulnerability_id": str(num_vulnerability_id),
            "num_intensity_bins": str(num_intensity_bins),
            "num_damage_bins": str(num_damage_bins),
            }

    logger.debug(f'{info}')

    dataset_path = pathlib.Path(os.path.join(run_dir, vulnerability_dataset))
    dataset_path.mkdir(exist_ok=True)
    for filepath in dataset_path.glob(vulnerability_parquet_filename.format('*')):
        os.remove(filepath)

    max_vulnerability_id_size = vulnerability_bloc_size // (num_intensity_bins * num_damage_bins * oasis_float.itemsize)
    num_step = ceil(num_vulnerability_id / max_vulnerability_id_size)
    for i, vuln_table in enumerate(iter_table(vulns_bin, num_intensity_bins, num_damage_bins, info, max_vulnerability_id_size)):
        logger.debug(f"step {i + 1}/{num_step}")
        pq.write_table(vuln_table, os.path.join(dataset_path, vulnerability_parquet_filename.format(i)))


parser = argparse.ArgumentParser()
parser.add_argument('-r', '--run-dir', help='path to the directory containing vulnerability.bin', default='static')
parser.add_argument('-v', '--logging-level', help='logging level (debug:10, info:20, warning:30, error:40, critical:50)',
                    default=30, type=int)


def main():
    kwargs = vars(parser.parse_args())

    # add handler to fm logger
    ch = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    ch.setFormatter(formatter)
    logger.addHandler(ch)
    logging_level = kwargs.pop('logging_level')
    logger.setLevel(logging_level)

    vulnerability_to_parquet(**kwargs)


if __name__ == "__main__":
    main()